{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1E5_p48NMGooxlUwbBdGU7XbdIq-0gCVr","timestamp":1729097192439}],"authorship_tag":"ABX9TyOHtTmn5OJrMVFbjf0mIrdi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[" QA = Define the z-statistic and explain its relationship to the standard normal distribution. How is the\n","z-statistic used in hypothesis testing?"],"metadata":{"id":"8Sa9dAjxJhrg"}},{"cell_type":"markdown","source":["The z-statistic is a standardized score that measures how many standard deviations a data point is from the mean of a population or sample. It is calculated by subtracting the population or sample mean from the individual data point and then dividing by the population or sample standard deviation.\n","The z-statistic is closely related to the standard normal distribution, which is a theoretical probability distribution with a mean of 0 and a standard deviation of 1. The standard normal distribution is used to calculate probabilities associated with z-scores. For example, the probability of a z-score being less than -1.96 is 0.025, meaning that there is a 2.5% chance of a data point being more than 1.96 standard deviations below the mean.\n","In hypothesis testing, the z-statistic is used to determine whether a sample mean is significantly different from a hypothesized population mean.\n","\n","The null hypothesis is that there is no difference between the sample mean and the population mean, while the alternative hypothesis is that there is a difference. The z-statistic is calculated using the sample mean, the population mean, and the population standard deviation\n","The calculated z-statistic is then compared to a critical value from the standard normal distribution. If the absolute value of the z-statistic is greater than the critical value, then the null hypothesis is rejected. This means that the sample mean is significantly different from the population mean. If the absolute value of the z-statistic is less than or equal to the critical value, then the null hypothesis is not rejected. This means that there is not enough evidence\n","\n"," to conclude that the sample mean is significantly different from the population mean.\n","\n"],"metadata":{"id":"pkXOTu19J200"}},{"cell_type":"markdown","source":[],"metadata":{"id":"HYW5R63tKJnj"}},{"cell_type":"markdown","source":["Question2 : What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is\n","very small (e.g., 0.01)?"],"metadata":{"id":"rix42Nn3KQKl"}},{"cell_type":"markdown","source":["P-Value: A Measure of Evidence\n","A p-value is a probability value that measures the strength of evidence against the null hypothesis in a statistical test. It represents the likelihood of observing a result as extreme or more extreme than the one obtained, assuming the null hypothesis is true.\n","\n","How P-Values are Used in Hypothesis Testing\n","State the Null Hypothesis: This is the hypothesis that there is no effect, no difference, or no relationship between variables.\n","Conduct the Test: A statistical test is performed to calculate the test statistic (e.g., z-statistic, t-statistic).\n","Determine the P-Value: The p-value is calculated based on the test statistic and the assumed distribution under the null hypothesis.\n","Compare to Alpha Level: The p-value is compared to a predetermined significance level (alpha).\n","If p-value < alpha: The null hypothesis is rejected, and the alternative hypothesis is accepted. This indicates that the observed data is unlikely to occur by chance if the null hypothesis were true.\n","If p-value >= alpha: The null hypothesis is not rejected. This means there is not enough evidence to conclude that the alternative hypothesis is true.\n","Meaning of a Small P-Value (e.g., 0.01)\n","A very small p-value, such as 0.01, suggests that the observed data is highly unlikely to occur if the null hypothesis were true. In other words, it provides strong evidence against the null hypothesis. This often leads to the rejection of the null hypothesis and the acceptance of the alternative hypothesis.\n","\n","For example: If a p-value of 0.01 is obtained in a medical study testing a new drug's effectiveness, it suggests that the observed improvement in patients is unlikely to be due to chance. This would provide strong evidence for the drug's efficacy.\n","\n","Important Note: A small p-value does not guarantee that the alternative hypothesis is true. It simply indicates that the observed data is inconsistent with the null hypothesis. Other factors, such as the study design and the quality of the data, should also be considered when interpreting results."],"metadata":{"id":"_H9lQlxxKii7"}},{"cell_type":"markdown","source":["Question3: Compare and contrast the binomial and Bernoulli distributions."],"metadata":{"id":"FhIvVFjnKkqZ"}},{"cell_type":"markdown","source":["Both the binomial and Bernoulli distributions are used to model the probability of a specific number of successes in a sequence of binary trials (trials with only two possible outcomes, e.g., success or failure). However, they differ in their scope and parameters.\n","\n","Bernoulli Distribution\n","Single trial: The Bernoulli distribution describes the probability of success or failure in a single binary trial.\n","Parameters:\n","p: The probability of success in a single trial.\n","Probability mass function (PMF):\n","P(X = x) = p^x * (1-p)^(1-x), where x is either 0 (failure) or 1 (success).\n","Binomial Distribution\n","Multiple trials: The binomial distribution describes the probability of a specific number of successes in a fixed number of independent Bernoulli trials.\n","Parameters:\n","n: The number of trials.\n","p: The probability of success in a single trial.\n","Probability mass function (PMF):\n","P(X = k) = C(n, k) * p^k * (1-p)^(n-k), where k is the number of successes (0 ≤ k ≤ n).\n","C(n, k) is the binomial coefficient, which represents the number of ways to choose k successes from n trials.\n","Comparison:\n","\n","Scope: The Bernoulli distribution is a special case of the binomial distribution with n = 1.\n","Parameters: Both distributions have a parameter p representing the probability of success. The binomial distribution also has a parameter n representing the number of trials.\n","PMF: The PMF of the Bernoulli distribution is simpler, as there are only two possible outcomes. The PMF of the binomial distribution involves the binomial coefficient and accounts for the different ways to achieve a specific number of successes.\n","In summary, the Bernoulli distribution focuses on a single binary trial, while the binomial distribution considers multiple independent binary trials. The binomial distribution is more flexible and can be used to model a wider range of scenarios involving repeated binary events.\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"monLMOzOKu1u"}},{"cell_type":"markdown","source":["Question 4: Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli\n","distribution?"],"metadata":{"id":"k0XCeIptLV_H"}},{"cell_type":"markdown","source":["The binomial distribution is used under the following conditions:\n","\n","Fixed number of trials (n): The experiment must consist of a fixed number of trials.\n","Independent trials: Each trial must be independent of the others. The outcome of one trial does not affect the outcome of another.\n","Binary outcomes: Each trial must have only two possible outcomes, typically labeled \"success\" and \"failure.\"\n","Constant probability of success (p): The probability of success (p) must remain constant for each trial.\n","The Bernoulli distribution is a special case of the binomial distribution with n = 1. In other words, a Bernoulli distribution describes the probability of success or failure in a single binary trial. The binomial distribution, on the other hand, describes the probability of a specific number of successes in a sequence of independent Bernoulli trials.\n","\n","\n","Therefore, the binomial distribution can be thought of as a generalization of the Bernoulli distribution to multiple trials. If you have a sequence of independent Bernoulli trials, you can use the binomial distribution to calculate the probability of any number of successes occurring."],"metadata":{"id":"8eWXb8pRLZG8"}},{"cell_type":"markdown","source":["Question5: What are the key properties of the Poisson distribution, and when is it appropriate to use this\n","distribution?"],"metadata":{"id":"3yLSEFMrLdz-"}},{"cell_type":"markdown","source":["The Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space. It is often used to model the number of occurrences of rare events.\n","\n","The key properties of the Poisson distribution are:\n","\n","Mean and variance are equal: The mean and variance of a Poisson distribution are both equal to the parameter λ.\n","No upper limit: The Poisson distribution can take on any non-negative integer value.\n","Rare events: The Poisson distribution is often used to model rare events, where the probability of an event occurring in a small interval is very small, but the probability of multiple events occurring in a larger interval is not negligible.\n","The Poisson distribution is appropriate to use when:\n","\n","The events being modeled are rare events.\n","The events occur independently of each other.\n","The rate of occurrence of the events is constant over time or space.\n","Some common examples of situations where the Poisson distribution is used include:\n","\n","The number of cars passing through an intersection in an hour.\n","The number of phone calls received by a customer service center in a day.\n","The number of radioactive particles emitted by a sample of material in a given time period.\n","The number of bacteria in a given volume of water.\n","In summary, the Poisson distribution is a useful tool for modeling the occurrence of rare events, and it is appropriate to use when the events being modeled are independent, occur at a constant rate, and are rare enough that the probability of multiple events occurring in a short interval is negligible."],"metadata":{"id":"jRtAb1niK1Ci"}},{"cell_type":"markdown","source":["Question6: Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a\n","PDF differ from a probability mass function (PMF)?"],"metadata":{"id":"3CzzLSceMFAO"}},{"cell_type":"markdown","source":["Probability Distribution\n","A probability distribution is a mathematical function that describes the likelihood of different outcomes occurring in a statistical experiment. It provides a way to quantify the uncertainty associated with random variables.\n","\n","Probability Density Function (PDF)\n","A probability density function (PDF) is used for continuous random variables. It gives the probability that a continuous random variable falls within a particular range of values. The PDF is defined such that the area under the curve between any two points represents the probability of the variable falling within that range.\n","\n","Key properties of a PDF:\n","\n","Non-negative: f(x) ≥ 0 for all x.\n","Total probability: ∫f(x)dx = 1, where the integral is taken over the entire range of x.\n","Probability Mass Function (PMF)\n","A probability mass function (PMF) is used for discrete random variables. It gives the probability that a discrete random variable takes on a specific value. The PMF assigns a probability to each possible outcome.\n","\n","Key properties of a PMF:\n","\n","Non-negative: P(X = x) ≥ 0 for all x.\n","Total probability: ∑P(X = x) = 1, where the sum is taken over all possible values of x.\n","Differences between PDF and PMF\n","Type of variable: PDF is used for continuous variables, while PMF is used for discrete variables.\n","Interpretation: The PDF represents the probability density at a point, while the PMF represents the probability of a specific value.\n","Calculation: For PDFs, probabilities are calculated by integrating over intervals. For PMFs, probabilities are calculated by summing over specific values."],"metadata":{"id":"FztK1plgMIZC"}},{"cell_type":"markdown","source":["Question7: Explain the Central Limit Theorem (CLT) with example."],"metadata":{"id":"uCUNq3UzMXNR"}},{"cell_type":"markdown","source":["The Central Limit Theorem (CLT) is a fundamental theorem in probability theory that states that the distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the\n","\n"," underlying distribution of the population. This is true as long as the population has a finite mean and variance.\n","\n","\n","Suppose we have a population with a skewed distribution. If we take many random samples of a fixed size from this population and calculate the mean of each sample, the distribution of these sample means will be approximately normal, regardless of the\n","\n"," skewness of the population distribution.\n","\n"],"metadata":{"id":"Zh6b09MvMd0P"}},{"cell_type":"markdown","source":["Question8: Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be a\n","\n","pplied instead?"],"metadata":{"id":"HEN6UxvhMsf5"}},{"cell_type":"markdown","source":["Z-Scores vs. T-Scores\n","Both z-scores and t-scores are used to standardize data and compare values to a distribution. However, they are used under different conditions:\n","Z-Scores\n","Known population standard deviation: Z-scores are used when the population standard deviation is known.\n","Large sample size: While not strictly required, z-scores are generally more accurate when the sample size is large (often considered 30 or more).\n","Standard normal distribution: Z-scores are based on the standard normal distribution, which has a mean of 0 and a standard deviation of 1.\n","T-Scores\n","Unknown population standard deviation: T-scores are used when the population standard deviation is unknown and must be estimated from the sample.\n","Small sample size: T-scores are particularly useful for small sample sizes, as they account for the uncertainty introduced by estimating the population standard deviation.\n","Student's t-distribution: T-scores are based on the Student's t-distribution, which has a wider shape than the standard normal distribution, especially for smaller sample sizes.\n","When to Use Which:\n","\n","Z-score: If you know the population standard deviation and have a large sample size, use a z-score.\n","T-score: If you don't know the population standard deviation or have a small sample size, use a t-score."],"metadata":{"id":"kotr9DflMzCC"}},{"cell_type":"markdown","source":["Question9: Given a sample mean of 105, a population mean of 100, a standard deviation of 15, and a sample\n","size of 25, calculate the z-score and p-value. Based on a significance level of 0.05, do you reject or fail to\n","reject the null hypothesis?\n","\n"," Task: Write Python code to calculate the z-score and p-value for the given data.\n","\n","Objective: Apply the formula for the z-score and interpret the p-value for hypothesis testing."],"metadata":{"id":"OU5svh5pNNNV"}},{"cell_type":"markdown","source":["import scipy.stats as stats\n","\n","# Given data\n","sample_mean = 105\n","population_mean = 100\n","standard_deviation = 15\n","sample_size = 25\n","significance_level = 0.05\n","\n","# Calculate the z-score\n","z_score = (sample_mean - population_mean) / (standard_deviation / (sample_size ** 0.5))\n","\n","# Calculate the p-value (two-tailed)\n","p_value = stats.norm.sf(abs(z_score)) * 2\n","\n","print(\"Z-score:\", z_score)\n","print(\"P-value:\", p_value)\n","\n","# Compare p-value to significance level\n","if p_value < significance_level:\n","    print(\"Reject the null hypothesis\")\n","else:\n","    print(\"Fail to reject the null hypothesis\")"],"metadata":{"id":"NJBHo6_iNdD4"}},{"cell_type":"markdown","source":["Question10: Simulate a binomial distribution with 10 trials and a probability of success of 0.6 using Python.\n","Generate 1,000 samples and plot the distribution. What is the expected mean and variance?\n","\n","Task: Use Python to generate the data, plot the distribution, and calculate the mean and variance.\n","\n","Objective: Understand the properties of a binomial distribution and verify them through simulation."],"metadata":{"id":"muddJIbBNhF6"}},{"cell_type":"markdown","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Set parameters\n","n_trials = 10\n","p_success = 0.6\n","num_samples = 1000\n","\n","# Generate binomial samples\n","samples = np.random.binomial(n_trials, p_success, num_samples)\n","\n","# Calculate expected mean and variance\n","expected_mean = n_trials * p_success\n","expected_variance = n_trials * p_success * (1 - p_success)\n","\n","# Plot the distribution\n","plt.hist(samples, bins=n_trials + 1, density=True)\n","plt.xlabel(\"Number of Successes\")\n","plt.ylabel(\"Probability\")\n","plt.title(\"Binomial Distribution (n=10, p=0.6)\")\n","plt.show()\n","\n","print(\"Expected Mean:\", expected_mean)\n","print(\"Expected Variance:\", expected_variance)"],"metadata":{"id":"R3CGfyDrNsKJ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"H9-RZyirNvh-"}}]}